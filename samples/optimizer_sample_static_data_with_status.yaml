
--- 
# Example 1
apiVersion: llmd.ai/v1alpha1
# Optimizing a variant, create only when the model is deployed and serving traffic
# this is for the collector the collect existing (previous) running metrics of the variant.
kind: Optimizer
metadata:
  # Unique name of the variant
  name: varaint-granite-13b-tp-4-a100
  namespace: default
  labels:
    inference.optimization/modelName: granite-13b
# This is essentially static input to the optimizer
spec:
  # OpenAI API compatible name of the model
  modelID: granite-13b
  # Add SLOs in configmap, add reference to this per model data
  # to avoid duplication and Move to ISOs when available
  sloClassRef:
    # Configmap name to load in the same namespace as optimizer object
    # we start with static (non-changing) ConfigMaps (for ease of implementation only)
    name: premium-slo
    # Key (modelID) present inside configmap
    key: granite-13b
  # Static profiled benchmarked data for a variant running on different accelerators
  modelProfile:
    accelerators:
      - acc: "A100"
        accCount: 1
        alpha: "20.58"
        beta: "0.41"
        maxBatchSize: 32
        atTokens: 512
      - acc: "G2"
        accCount: 1
        alpha: "17.15"
        beta: "0.34"
        maxBatchSize: 38
        atTokens: 512
status:
  # The collector discovers below allocation details, it is expected that model is running 
  # and serving inference request
  currentAlloc:
    accelerator: A100
    numReplicas: 4
    maxBatch: 16
    cost: 160
    itlAverage: 25.2
    waitAverage: 726.5
    load:
      arrivalRate: 40
      avgLength: 1024
      arrivalCOV: 1
      serviceCOV: 1
  # This is the output of Optimizer and ModelAnalyzer
  desiredOptimizedAlloc:
    lastRunTime: "2025-06-30T12:00:00Z"
    accelerator: G2
    numReplicas: 6
    maxBatch: 20
    cost: 125
    itlAverage: 20.5
    waitAverage: 100.0
    load:
      arrivalRate: 40
      avgLength: 1024
  # Denotes when the actuation was applied to controller like deployment or LWS or emitted prometheus metrics
  actuation:
    applied: true
    lastAttemptTime: "2025-06-30T12:01:15Z"
    lastSuccessTime: "2025-06-30T12:01:15Z"
--- 

# Example 2
apiVersion: llmd.ai/v1alpha1
# Optimizing a variant, create only when the model is deployed and serving traffic
# this is for the collector the collect existing (previous) running metrics of the variant.
kind: Optimizer
metadata:
  # Unique name of the variant
  name: variant-granite-13b-tp-2-a100
  namespace: default
  labels:
    inference.optimization/modelName: granite-13b
# This is essentially static input to the optimizer
spec:
  # OpenAI API compatible name of the model
  modelID: granite-13b
  # Add SLOs in configmap, add reference to this per model data
  # to avoid duplication and Move to ISOs when available
  sloClassRef:
    # Configmap name to load in the same namespace as optimizer object
    # we start with static (non-changing) ConfigMaps (for ease of implementation only)
    name: premium-slo
    # Key (modelID) present inside configmap
    key: granite-13b
  # Static profiled benchmarked data for a variant running on different accelerators
  modelProfile:
    accelerators:
      - acc: MIX300
        accCount: 1
        alpha: 20.58
        beta: 0.41
        maxBatchSize: 32
        atTokens: 512
      - acc: G2
        accCount: 1
        alpha: 17.15
        beta: 0.34
        maxBatchSize: 38
        atTokens: 512
status:
  # The collector discovers below allocation details, it is expected that model is running 
  # and serving inference request
  currentAlloc:
    accelerator: MIX300
    numReplicas: 2
    maxBatch: 16
    cost: 160
    itlAverage: 25.2
    waitAverage: 726.5
    load:
      arrivalRate: 40
      avgLength: 1024
      arrivalCOV: 1
      serviceCOV: 1
  # This is the output of Optimizer and ModelAnalyzer
  desiredOptimizedAlloc:
    lastRunTime: "2025-06-30T12:00:00Z"
    # We will change the resource requirements of the deployment 
    # based on optimizer output
    accelerator: G2
    numReplicas: 4
    maxBatch: 20
    cost: 125
    itlAverage: 20.5
    waitAverage: 100.0
    load:
      arrivalRate: 40
      avgLength: 1024
  # Denotes when the actuation was applied to controller like deployment or LWS or emitted prometheus metrics
  actuation:
    applied: true
    lastAttemptTime: "2025-06-30T12:01:15Z"
    lastSuccessTime: "2025-06-30T12:01:15Z"